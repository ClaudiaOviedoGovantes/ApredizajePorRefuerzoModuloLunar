{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351e27b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from DQN import DQN\n",
    "import numpy as np\n",
    "import pytorch_amd_hack_setup\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0523c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1]\n",
      "tensor([[ 0.0282, -0.0879,  0.1014, -0.0455],\n",
      "        [ 0.0282, -0.0879,  0.1014, -0.0455],\n",
      "        [ 0.0282, -0.0879,  0.1014, -0.0455],\n",
      "        [ 0.0282, -0.0879,  0.1014, -0.0455],\n",
      "        [ 0.0282, -0.0879,  0.1014, -0.0455],\n",
      "        [ 0.0282, -0.0879,  0.1014, -0.0455],\n",
      "        [ 0.0282, -0.0879,  0.1014, -0.0455],\n",
      "        [ 0.0282, -0.0879,  0.1014, -0.0455]], device='cuda:0')\n",
      "tensor([-0.0879,  0.1014, -0.0455,  0.0282, -0.0879,  0.1014, -0.0455,  0.0282])\n",
      "tensor([0.1014, 0.1014, 0.1014, 0.1014, 0.1014, 0.1014, 0.1014, 0.1014])\n"
     ]
    }
   ],
   "source": [
    "myModel = DQN(8, 4, 64).to('cuda').eval()\n",
    "\n",
    "inputData = [1]*8\n",
    "print(inputData)\n",
    "with torch.no_grad():\n",
    "    y = myModel(torch.tensor([inputData] * 8).to('cuda').float())\n",
    "print(y)\n",
    "print(y.cpu().gather(1, torch.tensor([1,2,3,0]*2).unsqueeze(1)).squeeze(-1))\n",
    "print(y.cpu().max(1)[0])\n",
    "\n",
    "# myModel.compile(\n",
    "#      loss = 'mse',\n",
    "#      metrics = ['mse'],\n",
    "#      optimizer = tf.keras.optimizers.Adam(learning_rate=0.001))\n",
    "# print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9df91676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box([ -2.5        -2.5       -10.        -10.         -6.2831855 -10.\n",
      "  -0.         -0.       ], [ 2.5        2.5       10.        10.         6.2831855 10.\n",
      "  1.         1.       ], (8,), float32)\n",
      "1\n",
      "[-0.00583735  1.4208131  -0.59127843  0.43966836  0.00677083  0.13393345\n",
      "  0.          0.        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\miniluz\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\aprendizaje-modulo-lunar-5laruUkD-py3.10\\lib\\site-packages\\pygame\\pkgdata.py:25: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_stream, resource_exists\n"
     ]
    }
   ],
   "source": [
    "from lunar import LunarLanderEnv\n",
    "\n",
    "lunar = LunarLanderEnv(render_mode=None)\n",
    "print(lunar.env.observation_space)\n",
    "print(lunar.env.action_space.sample())\n",
    "print(lunar.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64fc43f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "tf.Tensor(-0.02254521, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "lunarState = lunar.state\n",
    "lunarTensor = tf.convert_to_tensor([lunarState], dtype=np.float32)\n",
    "result = myModel(lunarTensor)\n",
    "print(np.argmax(result[0]))\n",
    "print(result[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad5e96ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-0.00458358 -0.         -0.          0.        ]\n",
      " [-0.         -0.02254522 -0.          0.        ]\n",
      " [-0.00458358 -0.         -0.          0.        ]\n",
      " [-0.         -0.         -0.          0.31878754]\n",
      " [-0.00458358 -0.         -0.          0.        ]\n",
      " [-0.         -0.02254522 -0.          0.        ]\n",
      " [-0.00458358 -0.         -0.          0.        ]\n",
      " [-0.         -0.         -0.          0.31878754]\n",
      " [-0.00458358 -0.         -0.          0.        ]\n",
      " [-0.         -0.02254522 -0.          0.        ]\n",
      " [-0.00458358 -0.         -0.          0.        ]\n",
      " [-0.         -0.         -0.          0.31878754]\n",
      " [-0.00458358 -0.         -0.          0.        ]\n",
      " [-0.         -0.02254522 -0.          0.        ]\n",
      " [-0.00458358 -0.         -0.          0.        ]\n",
      " [-0.         -0.         -0.          0.31878754]\n",
      " [-0.00458358 -0.         -0.          0.        ]\n",
      " [-0.         -0.02254522 -0.          0.        ]\n",
      " [-0.00458358 -0.         -0.          0.        ]\n",
      " [-0.         -0.         -0.          0.31878754]\n",
      " [-0.00458358 -0.         -0.          0.        ]\n",
      " [-0.         -0.02254522 -0.          0.        ]\n",
      " [-0.00458358 -0.         -0.          0.        ]\n",
      " [-0.         -0.         -0.          0.31878754]\n",
      " [-0.00458358 -0.         -0.          0.        ]\n",
      " [-0.         -0.02254522 -0.          0.        ]\n",
      " [-0.00458358 -0.         -0.          0.        ]\n",
      " [-0.         -0.         -0.          0.31878754]\n",
      " [-0.00458358 -0.         -0.          0.        ]\n",
      " [-0.         -0.02254522 -0.          0.        ]\n",
      " [-0.00458358 -0.         -0.          0.        ]\n",
      " [-0.         -0.         -0.          0.31878754]\n",
      " [-0.00458358 -0.         -0.          0.        ]\n",
      " [-0.         -0.02254522 -0.          0.        ]\n",
      " [-0.00458358 -0.         -0.          0.        ]\n",
      " [-0.         -0.         -0.          0.31878754]\n",
      " [-0.00458358 -0.         -0.          0.        ]\n",
      " [-0.         -0.02254522 -0.          0.        ]\n",
      " [-0.00458358 -0.         -0.          0.        ]\n",
      " [-0.         -0.         -0.          0.31878754]\n",
      " [-0.00458358 -0.         -0.          0.        ]\n",
      " [-0.         -0.02254522 -0.          0.        ]\n",
      " [-0.00458358 -0.         -0.          0.        ]\n",
      " [-0.         -0.         -0.          0.31878754]\n",
      " [-0.00458358 -0.         -0.          0.        ]\n",
      " [-0.         -0.02254522 -0.          0.        ]\n",
      " [-0.00458358 -0.         -0.          0.        ]\n",
      " [-0.         -0.         -0.          0.31878754]\n",
      " [-0.00458358 -0.         -0.          0.        ]\n",
      " [-0.         -0.02254522 -0.          0.        ]\n",
      " [-0.00458358 -0.         -0.          0.        ]\n",
      " [-0.         -0.         -0.          0.31878754]\n",
      " [-0.00458358 -0.         -0.          0.        ]\n",
      " [-0.         -0.02254522 -0.          0.        ]\n",
      " [-0.00458358 -0.         -0.          0.        ]\n",
      " [-0.         -0.         -0.          0.31878754]\n",
      " [-0.00458358 -0.         -0.          0.        ]\n",
      " [-0.         -0.02254522 -0.          0.        ]\n",
      " [-0.00458358 -0.         -0.          0.        ]\n",
      " [-0.         -0.         -0.          0.31878754]\n",
      " [-0.00458358 -0.         -0.          0.        ]\n",
      " [-0.         -0.02254522 -0.          0.        ]\n",
      " [-0.00458358 -0.         -0.          0.        ]\n",
      " [-0.         -0.         -0.          0.31878754]\n",
      " [-0.00458358 -0.         -0.          0.        ]\n",
      " [-0.         -0.02254522 -0.          0.        ]\n",
      " [-0.00458358 -0.         -0.          0.        ]\n",
      " [-0.         -0.         -0.          0.31878754]\n",
      " [-0.00458358 -0.         -0.          0.        ]\n",
      " [-0.         -0.02254522 -0.          0.        ]\n",
      " [-0.00458358 -0.         -0.          0.        ]\n",
      " [-0.         -0.         -0.          0.31878754]\n",
      " [-0.00458358 -0.         -0.          0.        ]\n",
      " [-0.         -0.02254522 -0.          0.        ]\n",
      " [-0.00458358 -0.         -0.          0.        ]\n",
      " [-0.         -0.         -0.          0.31878754]\n",
      " [-0.00458358 -0.         -0.          0.        ]\n",
      " [-0.         -0.02254522 -0.          0.        ]\n",
      " [-0.00458358 -0.         -0.          0.        ]\n",
      " [-0.         -0.         -0.          0.31878754]\n",
      " [-0.00458358 -0.         -0.          0.        ]\n",
      " [-0.         -0.02254522 -0.          0.        ]\n",
      " [-0.00458358 -0.         -0.          0.        ]\n",
      " [-0.         -0.         -0.          0.31878754]\n",
      " [-0.00458358 -0.         -0.          0.        ]\n",
      " [-0.         -0.02254522 -0.          0.        ]\n",
      " [-0.00458358 -0.         -0.          0.        ]\n",
      " [-0.         -0.         -0.          0.31878754]\n",
      " [-0.00458358 -0.         -0.          0.        ]\n",
      " [-0.         -0.02254522 -0.          0.        ]\n",
      " [-0.00458358 -0.         -0.          0.        ]\n",
      " [-0.         -0.         -0.          0.31878754]\n",
      " [-0.00458358 -0.         -0.          0.        ]\n",
      " [-0.         -0.02254522 -0.          0.        ]\n",
      " [-0.00458358 -0.         -0.          0.        ]\n",
      " [-0.         -0.         -0.          0.31878754]\n",
      " [-0.00458358 -0.         -0.          0.        ]\n",
      " [-0.         -0.02254522 -0.          0.        ]\n",
      " [-0.00458358 -0.         -0.          0.        ]\n",
      " [-0.         -0.         -0.          0.31878754]], shape=(100, 4), dtype=float32)\n",
      "tf.Tensor(\n",
      "[-0.00458358 -0.02254522 -0.00458358  0.31878754 -0.00458358 -0.02254522\n",
      " -0.00458358  0.31878754 -0.00458358 -0.02254522 -0.00458358  0.31878754\n",
      " -0.00458358 -0.02254522 -0.00458358  0.31878754 -0.00458358 -0.02254522\n",
      " -0.00458358  0.31878754 -0.00458358 -0.02254522 -0.00458358  0.31878754\n",
      " -0.00458358 -0.02254522 -0.00458358  0.31878754 -0.00458358 -0.02254522\n",
      " -0.00458358  0.31878754 -0.00458358 -0.02254522 -0.00458358  0.31878754\n",
      " -0.00458358 -0.02254522 -0.00458358  0.31878754 -0.00458358 -0.02254522\n",
      " -0.00458358  0.31878754 -0.00458358 -0.02254522 -0.00458358  0.31878754\n",
      " -0.00458358 -0.02254522 -0.00458358  0.31878754 -0.00458358 -0.02254522\n",
      " -0.00458358  0.31878754 -0.00458358 -0.02254522 -0.00458358  0.31878754\n",
      " -0.00458358 -0.02254522 -0.00458358  0.31878754 -0.00458358 -0.02254522\n",
      " -0.00458358  0.31878754 -0.00458358 -0.02254522 -0.00458358  0.31878754\n",
      " -0.00458358 -0.02254522 -0.00458358  0.31878754 -0.00458358 -0.02254522\n",
      " -0.00458358  0.31878754 -0.00458358 -0.02254522 -0.00458358  0.31878754\n",
      " -0.00458358 -0.02254522 -0.00458358  0.31878754 -0.00458358 -0.02254522\n",
      " -0.00458358  0.31878754 -0.00458358 -0.02254522 -0.00458358  0.31878754\n",
      " -0.00458358 -0.02254522 -0.00458358  0.31878754], shape=(100,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "lunarState = lunar.state\n",
    "lunarTensor = tf.convert_to_tensor([lunarState] * 100, dtype=np.float32)\n",
    "actions = tf.convert_to_tensor([0, 1, 0, 3] * 25, dtype=np.int32)\n",
    "# print(tf.one_hot(actions, 4))\n",
    "print(myModel(lunarTensor) * tf.one_hot(actions, 4))\n",
    "result = tf.reduce_sum(myModel(lunarTensor) * tf.one_hot(actions, 4), 1)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 64)\n",
      "(64,)\n",
      "(64, 64)\n",
      "(64,)\n",
      "(64, 4)\n",
      "(4,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Variable path=adam/iteration, shape=(), dtype=int64, value=1>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lunarState = lunar.state\n",
    "states = tf.convert_to_tensor([lunarState] * 100, dtype=np.float32)\n",
    "next_states =  tf.convert_to_tensor([lunarState] * 100, dtype=np.float32)\n",
    "rewards =  tf.convert_to_tensor([1] * 100, dtype=np.float32)\n",
    "dones =  tf.convert_to_tensor([0] * 100, dtype=np.float32)\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    # Get Q-values for the actions that were actually taken\n",
    "    q_values = tf.reduce_sum(myModel(states) * tf.one_hot(actions, 4), axis=1)\n",
    "    \n",
    "    # Get maximum Q-value for the next states from target network\n",
    "    next_q_values = tf.reduce_max(myModel(next_states), axis=1)\n",
    "    \n",
    "    # Compute the expected Q-values\n",
    "    expected_q_values = rewards + 0.9 * next_q_values * (1 - dones)\n",
    "    \n",
    "    # Compute the loss between the current and expected Q values\n",
    "    loss = tf.keras.losses.MeanSquaredError()(expected_q_values, q_values)\n",
    "\n",
    "gradients = tape.gradient(loss, myModel.trainable_weights)\n",
    "for gradient in gradients:\n",
    "    print(gradient.shape)\n",
    "\n",
    "optimizer.apply_gradients(zip(gradients, myModel.trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aprendizaje-modulo-lunar-5laruUkD-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
